{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 \u2014 Decorator quickstart\n",
        "\n",
        "This notebook demonstrates:\n",
        "\n",
        "- wrapping a function with `@gpu_profile`\n",
        "- the importance of `sync_fn` for CUDA-async frameworks (PyTorch)\n",
        "- capturing the summary programmatically\n",
        "\n",
        "If PyTorch/CUDA is not available, the GPU cells will be skipped.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from gpu_profile import gpu_profile\n",
        "\n",
        "# The decorator prints a report by default.\n",
        "@gpu_profile(interval_s=0.2, strict=False)\n",
        "def do_work():\n",
        "    # Replace this with real GPU work in your codebase.\n",
        "    import time\n",
        "    time.sleep(2)\n",
        "\n",
        "\n",
        "do_work()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# PyTorch example (optional)\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "except Exception as e:\n",
        "    torch = None\n",
        "    print('torch not available:', e)\n",
        "\n",
        "if torch is None or not torch.cuda.is_available():\n",
        "    print('CUDA not available; skipping PyTorch demo.')\n",
        "else:\n",
        "    from gpu_profile import gpu_profile\n",
        "\n",
        "    @gpu_profile(interval_s=0.1, sync_fn=torch.cuda.synchronize, warmup_s=0.2)\n",
        "    def matmul_bench(n=4096, steps=30):\n",
        "        a = torch.randn(n, n, device='cuda')\n",
        "        b = torch.randn(n, n, device='cuda')\n",
        "        for _ in range(steps):\n",
        "            _ = a @ b\n",
        "\n",
        "    matmul_bench()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Get results back as a structured object\n",
        "\n",
        "from gpu_profile import gpu_profile\n",
        "\n",
        "@gpu_profile(report=False, return_profile=True, interval_s=0.2, strict=False)\n",
        "def work_and_return_value():\n",
        "    import time\n",
        "    time.sleep(1)\n",
        "    return {'ok': True}\n",
        "\n",
        "res = work_and_return_value()\n",
        "print('value:', res.value)\n",
        "print('util mean:', res.gpu.util_gpu_mean)\n",
        "print('p95:', res.gpu.util_gpu_p95)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}