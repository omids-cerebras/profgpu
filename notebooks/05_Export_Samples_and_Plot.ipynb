{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# 05 â€” Export raw samples and plot\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- collecting raw samples with `store_samples=True`\n",
    "- exporting to CSV\n",
    "- plotting util.gpu over time (matplotlib)\n",
    "\n",
    "If PyTorch/CUDA is available, we generate a bursty workload. Otherwise we just sleep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except Exception:\n",
    "    torch = None\n",
    "\n",
    "from profgpu import GpuMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bursty_work(duration_s=6.0):\n",
    "    \"\"\"Alternates GPU work and CPU sleeps to create a visible utilization pattern.\"\"\"\n",
    "    if torch is None or not torch.cuda.is_available():\n",
    "        time.sleep(duration_s)\n",
    "        return\n",
    "\n",
    "    n = 4096\n",
    "    a = torch.randn(n, n, device=\"cuda\")\n",
    "    b = torch.randn(n, n, device=\"cuda\")\n",
    "    end = time.perf_counter() + duration_s\n",
    "    while time.perf_counter() < end:\n",
    "        # GPU burst\n",
    "        for _ in range(3):\n",
    "            _ = a @ b\n",
    "        # CPU gap\n",
    "        time.sleep(0.15)\n",
    "\n",
    "\n",
    "sync_fn = torch.cuda.synchronize if (torch is not None and torch.cuda.is_available()) else None\n",
    "\n",
    "with GpuMonitor(interval_s=0.1, store_samples=True, sync_fn=sync_fn, strict=False) as mon:\n",
    "    bursty_work(6.0)\n",
    "\n",
    "print(mon.summary.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "with open(\"gpu_samples.csv\", \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"t_s\", \"util_gpu\", \"util_mem\", \"mem_used_mb\", \"power_w\", \"temp_c\"])\n",
    "    for s in mon.samples:\n",
    "        w.writerow([s.t_s, s.util_gpu, s.util_mem, s.mem_used_mb, s.power_w, s.temp_c])\n",
    "\n",
    "print(\"Wrote gpu_samples.csv with\", len(mon.samples), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot util.gpu over time\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception as e:\n",
    "    plt = None\n",
    "    print(\"matplotlib not available:\", e)\n",
    "\n",
    "if plt is not None:\n",
    "    t = [s.t_s for s in mon.samples if s.util_gpu is not None]\n",
    "    u = [s.util_gpu for s in mon.samples if s.util_gpu is not None]\n",
    "    plt.figure()\n",
    "    plt.plot(t, u)\n",
    "    plt.xlabel(\"t (s)\")\n",
    "    plt.ylabel(\"util.gpu (%)\")\n",
    "    plt.title(\"GPU utilization over time\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
