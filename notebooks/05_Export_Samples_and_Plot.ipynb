{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# 05 — Export raw samples and plot\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- collecting raw samples with `store_samples=True`\n",
    "- exporting to CSV\n",
    "- plotting util.gpu over time (matplotlib)\n",
    "\n",
    "If PyTorch/CUDA is available, we generate a bursty workload. Otherwise we just sleep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cb/home/omids/ws/anaconda3/envs/profgpu/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except Exception:\n",
    "    torch = None\n",
    "\n",
    "from profgpu import GpuMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU 0] NVIDIA A10G\n",
      "  duration: 6.064s | samples: 58 @ 0.100s\n",
      "  util.gpu: mean 10.4% | p50 8.0% | p95 17.0% | max 17.0%\n",
      "  util.mem: mean 2.5%\n",
      "  memory: max used 2306 MB / total 23028 MB\n",
      "  power: mean 114.1 W | max 134.3 W\n",
      "  temp: max 30 °C\n",
      "  busy time (est): 0.632s\n",
      "  util trace: ▁▁▅▄▄▄▄▄█▄▄▄█▄▄▄██▄▄█▄▄▄█▄▄▄█▅▅▄█▅▄██▅▄▇\n"
     ]
    }
   ],
   "source": [
    "def bursty_work(duration_s=6.0):\n",
    "    \"\"\"Alternates GPU work and CPU sleeps to create a visible utilization pattern.\"\"\"\n",
    "    if torch is None or not torch.cuda.is_available():\n",
    "        time.sleep(duration_s)\n",
    "        return\n",
    "\n",
    "    n = 4096\n",
    "    a = torch.randn(n, n, device=\"cuda\")\n",
    "    b = torch.randn(n, n, device=\"cuda\")\n",
    "    end = time.perf_counter() + duration_s\n",
    "    while time.perf_counter() < end:\n",
    "        # GPU burst\n",
    "        for _ in range(3):\n",
    "            _ = a @ b\n",
    "        # CPU gap\n",
    "        time.sleep(0.15)\n",
    "\n",
    "\n",
    "sync_fn = torch.cuda.synchronize if (torch is not None and torch.cuda.is_available()) else None\n",
    "\n",
    "with GpuMonitor(interval_s=0.1, store_samples=True, sync_fn=sync_fn, strict=False) as mon:\n",
    "    bursty_work(6.0)\n",
    "\n",
    "print(mon.summary.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote gpu_samples.csv with 58 rows\n"
     ]
    }
   ],
   "source": [
    "# Export to CSV\n",
    "with open(\"gpu_samples.csv\", \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"t_s\", \"util_gpu\", \"util_mem\", \"mem_used_mb\", \"power_w\", \"temp_c\"])\n",
    "    for s in mon.samples:\n",
    "        w.writerow([s.t_s, s.util_gpu, s.util_mem, s.mem_used_mb, s.power_w, s.temp_c])\n",
    "\n",
    "print(\"Wrote gpu_samples.csv with\", len(mon.samples), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib not available: No module named 'matplotlib'\n"
     ]
    }
   ],
   "source": [
    "# Plot util.gpu over time\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception as e:\n",
    "    plt = None\n",
    "    print(\"matplotlib not available:\", e)\n",
    "\n",
    "if plt is not None:\n",
    "    t = [s.t_s for s in mon.samples if s.util_gpu is not None]\n",
    "    u = [s.util_gpu for s in mon.samples if s.util_gpu is not None]\n",
    "    plt.figure()\n",
    "    plt.plot(t, u)\n",
    "    plt.xlabel(\"t (s)\")\n",
    "    plt.ylabel(\"util.gpu (%)\")\n",
    "    plt.title(\"GPU utilization over time\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7f5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "profgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
