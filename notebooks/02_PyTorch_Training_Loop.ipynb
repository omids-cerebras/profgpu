{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# 02 — PyTorch training loop (synthetic)\n",
    "\n",
    "This notebook profiles a small training loop on synthetic data.\n",
    "\n",
    "It demonstrates a useful pattern:\n",
    "\n",
    "- profile one **epoch** at a time (stable window)\n",
    "- log/print the summary per epoch\n",
    "\n",
    "If PyTorch/CUDA is not available, the training cells will be skipped.\n",
    "\n",
    "> **PyTorch install:** `pip install torch --index-url https://download.pytorch.org/whl/cu124`\n",
    "> (works for any CUDA 12.x driver — there is no `cu126` index). Requires Python ≥ 3.9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cb/home/omids/ws/anaconda3/envs/profgpu/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "except Exception as e:\n",
    "    torch = None\n",
    "    print(\"torch not available:\", e)\n",
    "\n",
    "if torch is None or not torch.cuda.is_available():\n",
    "    print(\"CUDA not available; skipping training demo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "[GPU 0] NVIDIA A10G\n",
      "  duration: 0.164s | samples: 0 @ 0.200s\n",
      "  util.gpu: mean n/a | p50 n/a | p95 n/a | max n/a\n",
      "  util.mem: mean n/a\n",
      "  power: mean n/a | max n/a\n",
      "  temp: max n/a\n",
      "  busy time (est): n/a\n",
      "  notes: warmup ignored: first 0.20s\n",
      "\n",
      "epoch 1\n",
      "[GPU 0] NVIDIA A10G\n",
      "  duration: 0.172s | samples: 0 @ 0.200s\n",
      "  util.gpu: mean n/a | p50 n/a | p95 n/a | max n/a\n",
      "  util.mem: mean n/a\n",
      "  power: mean n/a | max n/a\n",
      "  temp: max n/a\n",
      "  busy time (est): n/a\n",
      "  notes: warmup ignored: first 0.20s\n",
      "\n",
      "epoch 2\n",
      "[GPU 0] NVIDIA A10G\n",
      "  duration: 0.172s | samples: 0 @ 0.200s\n",
      "  util.gpu: mean n/a | p50 n/a | p95 n/a | max n/a\n",
      "  util.mem: mean n/a\n",
      "  power: mean n/a | max n/a\n",
      "  temp: max n/a\n",
      "  busy time (est): n/a\n",
      "  notes: warmup ignored: first 0.20s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch is not None and torch.cuda.is_available():\n",
    "    from profgpu import GpuMonitor\n",
    "\n",
    "    class SmallMLP(nn.Module):\n",
    "        def __init__(self, d_in=1024, d_hidden=2048, d_out=10):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(d_in, d_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_hidden, d_out),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = SmallMLP().to(device)\n",
    "    opt = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    summaries = []\n",
    "    epochs = 3\n",
    "    batches_per_epoch = 500  # enough batches so each epoch lasts > 1 s\n",
    "    batch_size = 256\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # interval_s=0.05 for fast sampling; warmup_s=0 so short epochs still collect data\n",
    "        with GpuMonitor(interval_s=0.05, sync_fn=torch.cuda.synchronize, warmup_s=0.0) as mon:\n",
    "            for _ in range(batches_per_epoch):\n",
    "                x = torch.randn(batch_size, 1024, device=device)\n",
    "                y = torch.randint(0, 10, (batch_size,), device=device)\n",
    "\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                logits = model(x)\n",
    "                loss = loss_fn(logits, y)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "        summaries.append(mon.summary)\n",
    "        print(f\"epoch {epoch}\\n{mon.summary.format()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'duration_s': 0.1637926520779729, 'util_mean': nan, 'util_p95': nan, 'mem_max_mb': nan, 'power_mean_w': nan}\n",
      "{'epoch': 1, 'duration_s': 0.17233654204756021, 'util_mean': nan, 'util_p95': nan, 'mem_max_mb': nan, 'power_mean_w': nan}\n",
      "{'epoch': 2, 'duration_s': 0.17244787397794425, 'util_mean': nan, 'util_p95': nan, 'mem_max_mb': nan, 'power_mean_w': nan}\n"
     ]
    }
   ],
   "source": [
    "# Optional: turn summaries into a simple table\n",
    "\n",
    "if \"summaries\" in globals() and summaries:\n",
    "    rows = [\n",
    "        {\n",
    "            \"epoch\": i,\n",
    "            \"duration_s\": s.duration_s,\n",
    "            \"util_mean\": s.util_gpu_mean,\n",
    "            \"util_p95\": s.util_gpu_p95,\n",
    "            \"mem_max_mb\": s.mem_used_max_mb,\n",
    "            \"power_mean_w\": s.power_mean_w,\n",
    "        }\n",
    "        for i, s in enumerate(summaries)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        import pandas as pd\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        display(df)\n",
    "    except Exception:\n",
    "        for r in rows:\n",
    "            print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49ccf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "profgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
