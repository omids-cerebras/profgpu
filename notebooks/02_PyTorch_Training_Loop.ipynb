{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 \u2014 PyTorch training loop (synthetic)\n",
        "\n",
        "This notebook profiles a small training loop on synthetic data.\n",
        "\n",
        "It demonstrates a useful pattern:\n",
        "\n",
        "- profile one **epoch** at a time (stable window)\n",
        "- log/print the summary per epoch\n",
        "\n",
        "If PyTorch/CUDA is not available, the training cells will be skipped.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "except Exception as e:\n",
        "    torch = None\n",
        "    print('torch not available:', e)\n",
        "\n",
        "if torch is None or not torch.cuda.is_available():\n",
        "    print('CUDA not available; skipping training demo.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if torch is not None and torch.cuda.is_available():\n",
        "    from gpu_profile import GpuMonitor\n",
        "\n",
        "    class SmallMLP(nn.Module):\n",
        "        def __init__(self, d_in=1024, d_hidden=2048, d_out=10):\n",
        "            super().__init__()\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(d_in, d_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(d_hidden, d_out),\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.net(x)\n",
        "\n",
        "    device = torch.device('cuda')\n",
        "    model = SmallMLP().to(device)\n",
        "    opt = optim.AdamW(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    summaries = []\n",
        "    epochs = 3\n",
        "    batches_per_epoch = 200\n",
        "    batch_size = 256\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        with GpuMonitor(interval_s=0.2, sync_fn=torch.cuda.synchronize, warmup_s=0.2) as mon:\n",
        "            for _ in range(batches_per_epoch):\n",
        "                x = torch.randn(batch_size, 1024, device=device)\n",
        "                y = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                logits = model(x)\n",
        "                loss = loss_fn(logits, y)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "        summaries.append(mon.summary)\n",
        "        print(f\"epoch {epoch}\n",
        "{mon.summary.format()}\n",
        "\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: turn summaries into a simple table\n",
        "\n",
        "if 'summaries' in globals() and summaries:\n",
        "    rows = [\n",
        "        {\n",
        "            'epoch': i,\n",
        "            'duration_s': s.duration_s,\n",
        "            'util_mean': s.util_gpu_mean,\n",
        "            'util_p95': s.util_gpu_p95,\n",
        "            'mem_max_mb': s.mem_used_max_mb,\n",
        "            'power_mean_w': s.power_mean_w,\n",
        "        }\n",
        "        for i, s in enumerate(summaries)\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        df = pd.DataFrame(rows)\n",
        "        display(df)\n",
        "    except Exception:\n",
        "        for r in rows:\n",
        "            print(r)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}